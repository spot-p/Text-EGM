{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"17XfqM49vlzk-W82oJb9HPkjQdHgAloPZ","authorship_tag":"ABX9TyManyfD1CaeKG32dfHcwlRU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Introduction:\n","This notebook enables a step wise reproduction of the study presented in the paper:\n","\n","> **Interpretation of Intracardiac Electrograms Through Textual Representations**\n","> William Jongwon Han, Diana Gomez, Avi Alok, Chaojing Duan, Michael A. Rosenberg, Douglas Weber, Emerson Liu, Ding Zhao\n","arXiv:2402.01115\n","Accepted at CHIL 2024\n"],"metadata":{"id":"iimHNrQb4CBs"}},{"cell_type":"markdown","source":["# Notebook Overview:\n","\n","This notebook is designed to replicate the experiments and analyses conducted in the above paper within Colab, however it can also be executed in a similar captive environment.\n","\n","It includes:\n","\n","\n","*  Data Preprocessing: Fetching loading and preparing the Intracardiac Atrial Fibrillation Database for model training.\n","\n","*  Training: Fine-tuning 4 masked language models on the processed EGM data.\n","\n","*  Inference: Assessing model performance based on MSE, MAE and AFib classification tasks.\n","\n","*  Visualization: Visualizing, the reconstructed signal, attribution and attention scores to understand model inference.\n","\n","\n","By following this notebook, you can explore the innovative methodology proposed in the paper and gain hands-on experience with the techniques discussed.\n","\n","**Limitation:** While the paper evaluates performance on both internal and external datasets, only the external dataset is publicly available due to the sensitive nature of clinical data. The public dataset contains only a single (positive) class, which may introduce bias or limit the reproducibility and generalization of the results. Users replicating the study should be aware that this class imbalance can significantly affect both training and evaluation metrics especially the classification metrics."],"metadata":{"id":"2v21b55U_AY6"}},{"cell_type":"markdown","source":["### Clone this repository"],"metadata":{"id":"lmp4LL5yGB6i"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"sX81BkMPBL0I"},"outputs":[],"source":["!git clone https://github.com/spot-p/Text-EGM.git"]},{"cell_type":"markdown","source":["### Move into the main directory and install dependencies."],"metadata":{"id":"87-sh8YTGKwa"}},{"cell_type":"code","source":["%cd Text-EGM\n","!pip install -r colab_requirements.txt"],"metadata":{"id":"cbtUvnvcF0_a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1746208492494,"user_tz":240,"elapsed":5,"user":{"displayName":"Swaroop Potdar","userId":"07645468143369010864"}},"outputId":"8f87419e-6de4-48b7-f574-1cd2e95349eb"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/Text-EGM\n"]}]},{"cell_type":"markdown","source":["## Data PreProcessing:"],"metadata":{"id":"jLeCI0GdCLnk"}},{"cell_type":"markdown","source":["### Download the external dataset from physionet.org"],"metadata":{"id":"XQ-reOBbGd78"}},{"cell_type":"code","source":["%cd preprocess\n","#!wget https://physionet.org/static/published-projects/iafdb/intracardiac-atrial-fibrillation-database-1.0.0.zip\n","!gdown 'https://drive.google.com/uc?export=download&id=1XYnKKhNOMuLk5madEJLH-G4YISidu0R-'\n","!unzip intracardiac-atrial-fibrillation-database-1.0.0\n"],"metadata":{"id":"tbeWfaauGpZU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Execute the preprocessing script"],"metadata":{"id":"Mv8C9TuWHEQF"}},{"cell_type":"code","source":["!python preprocess_intra.py --path intracardiac-atrial-fibrillation-database-1.0.0\n","%cd .."],"metadata":{"id":"XD5qVAxlHIxV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Training"],"metadata":{"id":"jgsGipTBHKtJ"}},{"cell_type":"markdown","source":["### Train each of the 4 models with processed data"],"metadata":{"id":"JrVp9PeuImRZ"}},{"cell_type":"markdown","source":["##### With L4 GPU the average execution time per epoch is 37 minutes"],"metadata":{"id":"XbZQez3QMtES"}},{"cell_type":"code","source":["!python train.py --device=cuda:0 --batch=4 --patience=5 --model=big --mask=0.75 --use_ce --norm_loss=0.1 --warmup=500 --epochs=20"],"metadata":{"id":"XSZ-9j1vItNb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python train.py --device=cuda:0 --batch=4 --patience=5 --model=clin_bird --mask=0.75 --use_ce --norm_loss=0.1 --warmup=500 --epochs=20"],"metadata":{"id":"I3SrQ9KeI4xr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python train.py --device=cuda:0 --batch=4 --patience=5 --model=long --mask=0.75 --use_ce --norm_loss=0.1 --warmup=500 --epochs=20"],"metadata":{"id":"ssgVfU2wI4pa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python train.py --device=cuda:0 --batch=4 --patience=5 --model=clin_long --mask=0.75 --use_ce --norm_loss=0.1 --warmup=500 --epochs=20"],"metadata":{"id":"6z-hAIONI4fS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Inference\n","##### ** The inference metrics (MSE,MAE,Accuracy and derived) for the below combinations would be saved into results.txt in the root folder with associated arguments used."],"metadata":{"id":"E1AZZZyyNI5c"}},{"cell_type":"markdown","source":["#### Perform Inference without counter-factuals/ inputs perturbations. The --checkpoint arugment would be different if the above training arguments are changed."],"metadata":{"id":"jbe4jjxmNNZ3"}},{"cell_type":"code","source":["!python inference.py --device=cuda:0 --batch=1 --checkpoint='saved_best_0.0001_4_5_0.01_big_True_0.75_1.0_1.0_False_0.1_False_False_False' --model=big --inference --mask=0.75\n"],"metadata":{"id":"aMfkYQIKOwWB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python inference.py --device=cuda:0 --batch=1 --checkpoint='saved_best_0.0001_4_5_0.01_clin_bird_True_0.75_1.0_1.0_False_0.1_False_False_False' --model=clin_bird --inference --mask=0.75\n"],"metadata":{"id":"GZRawnMTOzTW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python inference.py --device=cuda:0 --batch=1 --checkpoint='saved_best_0.0001_4_5_0.01_long_True_0.75_1.0_1.0_False_0.1_False_False_False' --model=long --inference --mask=0.75\n"],"metadata":{"id":"pCXwbvesNpgq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python inference.py --device=cuda:0 --batch=1 --checkpoint='saved_best_0.0001_4_5_0.01_clin_long_True_0.75_1.0_1.0_False_0.1_False_False_False' --model=clin_long --inference --mask=0.75\n"],"metadata":{"id":"cpbfu6L6Oc4s"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Perform inference with combinations of counterfactuals / input perturbations."],"metadata":{"id":"kj5oyLfAPLKA"}},{"cell_type":"code","source":["# All four with label flipping\n","!python inference.py --device=cuda:0 --batch=1 --checkpoint='saved_best_0.0001_4_5_0.01_long_True_0.75_1.0_1.0_False_0.1_False_False_False' --model=long --inference --mask=0.75 --LF\n","!python inference.py --device=cuda:0 --batch=1 --checkpoint='saved_best_0.0001_4_5_0.01_clin_long_True_0.75_1.0_1.0_False_0.1_False_False_False' --model=clin_long --inference --mask=0.75 --LF\n","!python inference.py --device=cuda:0 --batch=1 --checkpoint='saved_best_0.0001_4_5_0.01_clin_bird_True_0.75_1.0_1.0_False_0.1_False_False_False' --model=clin_bird --inference --mask=0.75 --LF\n","!python inference.py --device=cuda:0 --batch=1 --checkpoint='saved_best_0.0001_4_5_0.01_big_True_0.75_1.0_1.0_False_0.1_False_False_False' --model=big --inference --mask=0.75 --LF\n","\n","# All four with token substitution\n","!python inference.py --device=cuda:0 --batch=1 --checkpoint='saved_best_0.0001_4_5_0.01_long_True_0.75_1.0_1.0_False_0.1_False_False_False' --model=long --inference --mask=0.75 --TS\n","!python inference.py --device=cuda:0 --batch=1 --checkpoint='saved_best_0.0001_4_5_0.01_clin_long_True_0.75_1.0_1.0_False_0.1_False_False_False' --model=clin_long --inference --mask=0.75 --TS\n","!python inference.py --device=cuda:0 --batch=1 --checkpoint='saved_best_0.0001_4_5_0.01_clin_bird_True_0.75_1.0_1.0_False_0.1_False_False_False' --model=clin_bird --inference --mask=0.75 --TS\n","!python inference.py --device=cuda:0 --batch=1 --checkpoint='saved_best_0.0001_4_5_0.01_big_True_0.75_1.0_1.0_False_0.1_False_False_False' --model=big --inference --mask=0.75 --TS\n","\n","# All four with label flipping and token substitution\n","!python inference.py --device=cuda:0 --batch=1 --checkpoint='saved_best_0.0001_4_5_0.01_long_True_0.75_1.0_1.0_False_0.1_False_False_False' --model=long --inference --mask=0.75 --LF --TS\n","!python inference.py --device=cuda:0 --batch=1 --checkpoint='saved_best_0.0001_4_5_0.01_clin_long_True_0.75_1.0_1.0_False_0.1_False_False_False' --model=clin_long --inference --mask=0.75 --LF --TS\n","!python inference.py --device=cuda:0 --batch=1 --checkpoint='saved_best_0.0001_4_5_0.01_clin_bird_True_0.75_1.0_1.0_False_0.1_False_False_False' --model=clin_bird --inference --mask=0.75 --LF --TS\n","!python inference.py --device=cuda:0 --batch=1 --checkpoint='saved_best_0.0001_4_5_0.01_big_True_0.75_1.0_1.0_False_0.1_False_False_False' --model=big --inference --mask=0.75 --LF --TS\n"],"metadata":{"id":"W3aoNuCrQX0E"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Visualization"],"metadata":{"id":"Cl8WcQCVRtzP"}},{"cell_type":"code","source":["%cd visualize"],"metadata":{"id":"_dqxgmMhRmVB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### To visualize the masked reconstructed signal for each model"],"metadata":{"id":"3avLiseswf9q"}},{"cell_type":"code","source":["!python stitching.py --checkpoint='saved_best_0.0001_4_5_0.01_long_True_0.75_1.0_1.0_False_0.1_False_False_False' --instance=100 --time=1\n","!python stitching.py --checkpoint='saved_best_0.0001_4_5_0.01_long_True_0.75_1.0_1.0_False_0.1_False_False_False' --instance=100 --time=2\n","\n","!python stitching.py --checkpoint='saved_best_0.0001_4_5_0.01_clin_long_True_0.75_1.0_1.0_False_0.1_False_False_False' --instance=100 --time=1\n","!python stitching.py --checkpoint='saved_best_0.0001_4_5_0.01_clin_long_True_0.75_1.0_1.0_False_0.1_False_False_False' --instance=100 --time=2\n","\n","!python stitching.py --checkpoint='saved_best_0.0001_4_5_0.01_clin_bird_True_0.75_1.0_1.0_False_0.1_False_False_False' --instance=100 --time=1\n","!python stitching.py --checkpoint='saved_best_0.0001_4_5_0.01_clin_bird_True_0.75_1.0_1.0_False_0.1_False_False_False' --instance=100 --time=2\n","\n","!python stitching.py --checkpoint='saved_best_0.0001_4_5_0.01_big_True_0.75_1.0_1.0_False_0.1_False_False_False' --instance=100 --time=1\n","!python stitching.py --checkpoint='saved_best_0.0001_4_5_0.01_big_True_0.75_1.0_1.0_False_0.1_False_False_False' --instance=100 --time=2"],"metadata":{"id":"BvZO38r0weQy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### To visualize the token importance for reconstruction and forecast / attribution scores for each model. Switch out the respective checkpoints for attribution scores mapped across time and frequency domain."],"metadata":{"id":"wdtv9GOYw6wr"}},{"cell_type":"code","source":["!python int_grad.py --checkpoint=saved_best_0.0001_5_3_0.01_long_True_0.75_1.0_1.0_False_0.1_False_False_False --device=cuda:0 --model=long --afibmask\n","!python int_grad.py --checkpoint=saved_best_0.0001_5_3_0.01_long_True_0.75_1.0_1.0_False_0.1_False_False_False --device=cuda:0 --model=long --pre --afibmask\n","!python int_grad.py --checkpoint=saved_best_0.0001_5_3_0.01_long_True_0.75_1.0_1.0_False_0.1_False_False_False --device=cuda:0 --model=long\n","!python int_grad.py --checkpoint=saved_best_0.0001_5_3_0.01_long_True_0.75_1.0_1.0_False_0.1_False_False_False --device=cuda:0 --model=long --pre\n","\n","!python int_grad.py --checkpoint=saved_best_0.0001_4_3_0.01_clin_long_True_0.75_1.0_1.0_False_0.1_False_False_False --device=cuda:0 --model=clin_long --afibmask\n","!python int_grad.py --checkpoint=saved_best_0.0001_4_3_0.01_clin_long_True_0.75_1.0_1.0_False_0.1_False_False_False --device=cuda:0 --model=clin_long --pre --afibmask\n","!python int_grad.py --checkpoint=saved_best_0.0001_4_3_0.01_clin_long_True_0.75_1.0_1.0_False_0.1_False_False_False --device=cuda:0 --model=clin_long\n","!python int_grad.py --checkpoint=saved_best_0.0001_4_3_0.01_clin_long_True_0.75_1.0_1.0_False_0.1_False_False_False --device=cuda:0 --model=clin_long --pre\n","\n","!python int_grad.py --checkpoint=saved_best_0.0001_4_5_0.01_clin_bird_True_0.75_1.0_1.0_False_0.1_False_False_False --device=cuda:0 --model=clin_bird --afibmask\n","!python int_grad.py --checkpoint=saved_best_0.0001_4_5_0.01_clin_bird_True_0.75_1.0_1.0_False_0.1_False_False_False --device=cuda:0 --model=clin_bird --pre --afibmask\n","!python int_grad.py --checkpoint=saved_best_0.0001_4_5_0.01_clin_bird_True_0.75_1.0_1.0_False_0.1_False_False_False --device=cuda:0 --model=clin_bird\n","!python int_grad.py --checkpoint=saved_best_0.0001_4_5_0.01_clin_bird_True_0.75_1.0_1.0_False_0.1_False_False_False --device=cuda:0 --model=clin_bird --pre\n","\n","!python int_grad.py --checkpoint=saved_best_0.0001_4_5_0.01_big_True_0.75_1.0_1.0_False_0.1_False_False_False --device=cuda:0 --model=big --afibmask\n","!python int_grad.py --checkpoint=saved_best_0.0001_4_5_0.01_big_True_0.75_1.0_1.0_False_0.1_False_False_False --device=cuda:0 --model=big --pre --afibmask\n","!python int_grad.py --checkpoint=saved_best_0.0001_4_5_0.01_big_True_0.75_1.0_1.0_False_0.1_False_False_False --device=cuda:0 --model=big\n","!python int_grad.py --checkpoint=saved_best_0.0001_4_5_0.01_big_True_0.75_1.0_1.0_False_0.1_False_False_False --device=cuda:0 --model=big --pre\n"],"metadata":{"id":"St2B2YrCx720"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### To generate attention scores mapped across time and frequency domain for respective models with perturbed inputs. Switch out the the respective model checkpoints for their respective attention scores."],"metadata":{"id":"dBegOAUqz-dg"}},{"cell_type":"code","source":["!python viz_attentions.py --checkpoint=saved_best_0.0001_4_5_0.01_long_True_0.75_1.0_1.0_False_0.1_False_False_False --device=cuda:0 --model=long --afibmask\n","!python viz_attentions.py --checkpoint=saved_best_0.0001_4_5_0.01_long_True_0.75_1.0_1.0_False_0.1_False_False_False --device=cuda:0 --model=long --pre --afibmask\n","!python viz_attentions.py --checkpoint=saved_best_0.0001_4_5_0.01_long_True_0.75_1.0_1.0_False_0.1_False_False_False --device=cuda:0 --model=long\n","!python viz_attentions.py --checkpoint=saved_best_0.0001_4_5_0.01_long_True_0.75_1.0_1.0_False_0.1_False_False_False --device=cuda:0 --model=long --pre\n","\n","!python viz_attentions.py --checkpoint=saved_best_0.0001_4_5_0.01_clin_long_True_0.75_1.0_1.0_False_0.1_False_False_False --device=cuda:0 --model=clin_long --afibmask\n","!python viz_attentions.py --checkpoint=saved_best_0.0001_4_5_0.01_clin_long_True_0.75_1.0_1.0_False_0.1_False_False_False --device=cuda:0 --model=clin_long --pre --afibmask\n","!python viz_attentions.py --checkpoint=saved_best_0.0001_4_5_0.01_clin_long_True_0.75_1.0_1.0_False_0.1_False_False_False --device=cuda:0 --model=clin_long\n","!python viz_attentions.py --checkpoint=saved_best_0.0001_4_5_0.01_clin_long_True_0.75_1.0_1.0_False_0.1_False_False_False --device=cuda:0 --model=clin_long --pre\n","\n","!python viz_attentions.py --checkpoint=saved_best_0.0001_4_5_0.01_clin_bird_True_0.75_1.0_1.0_False_0.1_False_False_False --device=cuda:0 --model=clin_bird --afibmask\n","!python viz_attentions.py --checkpoint=saved_best_0.0001_4_5_0.01_clin_bird_True_0.75_1.0_1.0_False_0.1_False_False_False --device=cuda:0 --model=clin_bird --pre --afibmask\n","!python viz_attentions.py --checkpoint=saved_best_0.0001_4_5_0.01_clin_bird_True_0.75_1.0_1.0_False_0.1_False_False_False --device=cuda:0 --model=clin_bird\n","!python viz_attentions.py --checkpoint=saved_best_0.0001_4_5_0.01_clin_bird_True_0.75_1.0_1.0_False_0.1_False_False_False --device=cuda:0 --model=clin_bird --pre\n","\n","!python viz_attentions.py --checkpoint=saved_best_0.0001_4_5_0.01_big_True_0.75_1.0_1.0_False_0.1_False_False_False --device=cuda:0 --model=big --afibmask\n","!python viz_attentions.py --checkpoint=saved_best_0.0001_4_5_0.01_big_True_0.75_1.0_1.0_False_0.1_False_False_False --device=cuda:0 --model=big --pre --afibmask\n","!python viz_attentions.py --checkpoint=saved_best_0.0001_4_5_0.01_big_True_0.75_1.0_1.0_False_0.1_False_False_False --device=cuda:0 --model=big\n","!python viz_attentions.py --checkpoint=saved_best_0.0001_4_5_0.01_big_True_0.75_1.0_1.0_False_0.1_False_False_False --device=cuda:0 --model=big --pre\n"],"metadata":{"id":"2YpXhvdk0wE1"},"execution_count":null,"outputs":[]}]}